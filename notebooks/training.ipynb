{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 12:19:15.444129: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-18 12:19:15.488461: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-09-18 12:19:15.489048: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-18 12:19:16.379822: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/enrico/univr/Tesi/.env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    TFBertTokenizer,\n",
    "    TFVisionTextDualEncoderModel\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args = {\n",
    "    'image_path_to_caption_file': '/home/enrico/univr/Tesi/trainer/image_path_to_caption_train.json',\n",
    "    'images_dir': '/home/enrico/univr/Tesi/images',\n",
    "    'vision_model_name_or_path': \"google/vit-base-patch16-224\",\n",
    "    'text_model_name_or_path': 'bert-base-uncased',\n",
    "    'train_split': .8,\n",
    "    'num_train_epochs': 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 12:19:20.447997: I tensorflow_text/core/kernels/fast_bert_normalizer_model_builder.cc:211] CharacterSet built (lower_case_nfd_strip_accents=1). Trie data size (int32): 35072. Normalized string pool size (byte): 111208\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFViTModel: ['classifier.weight', 'classifier.bias']\n",
      "- This IS expected if you are initializing TFViTModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFViTModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFViTModel were not initialized from the PyTorch model and are newly initialized: ['vit.pooler.dense.weight', 'vit.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n",
      "The projection layer and logit scale weights `['visual_projection.weight', 'text_projection.weight', 'logit_scale']` are newly initialized. You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(model_args['vision_model_name_or_path'])\n",
    "tokenizer = TFBertTokenizer.from_pretrained(model_args['text_model_name_or_path'])\n",
    "\n",
    "model = TFVisionTextDualEncoderModel.from_vision_text_pretrained(text_model_name_or_path=model_args['text_model_name_or_path']\n",
    "        ,vision_model_name_or_path= model_args['vision_model_name_or_path'] \n",
    "    )\n",
    "\n",
    "# if model_args.freeze_vision_model:\n",
    "model.vision_model.trainable = False\n",
    "\n",
    "# if model_args.freeze_text_model:\n",
    "model.text_model.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group all captions together having the same image path\n",
    "def load_img_text_pairs(image_path_to_caption_file,images_dir):\n",
    "    with open(image_path_to_caption_file, 'r') as f:\n",
    "        image_path_to_caption_file = json.load(f)\n",
    "    captions = []\n",
    "    images = []\n",
    "    for image_path in image_path_to_caption_file.keys():\n",
    "        caption_list = image_path_to_caption_file[image_path]\n",
    "        captions.extend(caption_list)\n",
    "        images.extend([os.path.join(images_dir,image_path)] * len(caption_list))  \n",
    "    return (images, captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_text(inputs):\n",
    "  return tf.strings.regex_replace(inputs,\n",
    "                                  r\"!\\\"#$%&\\(\\)\\*\\+.,-/:;=?@\\[\\\\\\]^_`{|}~\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_to_square(image):\n",
    "    height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "    if height > width:\n",
    "        image = tf.image.crop_to_bounding_box(\n",
    "            image, (height - width) // 2, 0, width, width)\n",
    "    elif width > height:\n",
    "        image = tf.image.crop_to_bounding_box(\n",
    "            image, 0, (width - height) // 2, height, height)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2, 4), dtype=int32, numpy=\n",
       "array([[[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]],\n",
       "\n",
       "       [[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]],\n",
       "\n",
       "       [[1, 2, 3, 4],\n",
       "        [5, 6, 7, 8]]], dtype=int32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tf.constant([[[1, 2, 3,4], [ 5, 6,7,8]],[[1, 2, 3,4], [ 5, 6,7,8]],[[1, 2, 3,4], [ 5, 6,7,8]]])\n",
    "x = tf.transpose(x, perm=[2,0,1])\n",
    "x = tf.transpose(x, perm=[1,2,0])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tf_datasets(image_path_to_caption_file, images_dir, image_processor, caption_tokenizer, train_batch_size=64, test_batch_size=32, train_split=.8):\n",
    "    images, captions = load_img_text_pairs(image_path_to_caption_file, images_dir)\n",
    "    ds = standardize_text(captions)\n",
    "    ds = caption_tokenizer(captions)\n",
    "    del ds['token_type_ids']\n",
    "    ds['image_path'] = images\n",
    "    tf_dataset = tf.data.Dataset.from_tensor_slices(ds)\n",
    "    \n",
    "    def load_image(sample):\n",
    "        image_path = sample['image_path']\n",
    "        image = tf.io.read_file(image_path)\n",
    "        image = tf.image.decode_image(\n",
    "            image, channels=3, expand_animations=False)\n",
    "        image = crop_to_square(image)\n",
    "        image = tf.image.resize(\n",
    "            image, list(image_processor.size.values()), method=\"bicubic\", antialias=True)\n",
    "        image = image / 255.0\n",
    "        image = (image - image_processor.image_mean) / image_processor.image_std\n",
    "        # Convert to channels-first\n",
    "        image = tf.transpose(image, perm=[2, 0, 1])\n",
    "        sample[\"pixel_values\"] = image\n",
    "        del sample['image_path']\n",
    "        return sample\n",
    "\n",
    "    def transform(sample, seed):\n",
    "        image = load_image(sample)['pixel_values']\n",
    "        new_seed = tf.random.experimental.stateless_split(seed, num=1)[0]\n",
    "        # Random brightness\n",
    "        image = tf.image.stateless_random_brightness(\n",
    "            image, max_delta=0.5, seed=new_seed)\n",
    "        # Random contrast\n",
    "        image = tf.image.stateless_random_contrast(\n",
    "            image, lower=0.1, upper=0.9, seed=new_seed)\n",
    "        image = tf.transpose(image, perm=[1, 2, 0])\n",
    "        image = tf.image.stateless_random_hue(image,.25,seed=seed)\n",
    "        # Rotation\n",
    "        image = tf.image.rot90(image)\n",
    "        image = tf.transpose(image, perm=[2, 0, 1])\n",
    "        sample[\"pixel_values\"] = image\n",
    "        return sample\n",
    "\n",
    "    # Create a generator.\n",
    "    rng = tf.random.Generator.from_seed(123, alg='philox')\n",
    "\n",
    "    # Create a wrapper function for updating seeds.\n",
    "    def update_seed(x):\n",
    "        seed = rng.make_seeds(2)[0]\n",
    "        image= transform(x, seed)\n",
    "        print(image)\n",
    "        return image\n",
    "\n",
    "    train_len = round(len(tf_dataset) * float(train_split))\n",
    "    shuffled = tf_dataset.shuffle(len(tf_dataset), seed=42, reshuffle_each_iteration=False)\n",
    "    train = shuffled\\\n",
    "                    .take(train_len)\\\n",
    "                    .map(update_seed, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                    .batch(train_batch_size)\\\n",
    "                    .prefetch(tf.data.AUTOTUNE)\n",
    "    test = shuffled\\\n",
    "                    .skip(train_len)\\\n",
    "                    .map(load_image, num_parallel_calls=tf.data.AUTOTUNE)\\\n",
    "                    .batch(test_batch_size)\\\n",
    "                    .prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': <tf.Tensor 'args_2:0' shape=(189,) dtype=int64>, 'attention_mask': <tf.Tensor 'args_0:0' shape=(189,) dtype=int64>, 'pixel_values': <tf.Tensor 'transpose_2:0' shape=(3, 224, 224) dtype=float32>}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(64, 189), dtype=int64, numpy=\n",
       " array([[  101,  3393, 21877, ...,     0,     0,     0],\n",
       "        [  101, 22949,  5428, ...,     0,     0,     0],\n",
       "        [  101,  2009,  2036, ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2009,  2036, ...,     0,     0,     0],\n",
       "        [  101,  9665,  2317, ...,     0,     0,     0],\n",
       "        [  101, 10250, 19629, ...,     0,     0,     0]])>,\n",
       " 'attention_mask': <tf.Tensor: shape=(64, 189), dtype=int64, numpy=\n",
       " array([[1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0],\n",
       "        [1, 1, 1, ..., 0, 0, 0]])>,\n",
       " 'pixel_values': <tf.Tensor: shape=(64, 3, 224, 224), dtype=float32, numpy=\n",
       " array([[[[ 0.08401372,  0.092843  ,  0.03194861, ...,  0.51255864,\n",
       "            0.5138095 ,  0.5283047 ],\n",
       "          [ 0.10082122,  0.13096133,  0.14288099, ...,  0.5245258 ,\n",
       "            0.51931965,  0.5209845 ],\n",
       "          [ 0.01195184,  0.00840572,  0.06190491, ...,  0.5095011 ,\n",
       "            0.51123047,  0.5043729 ],\n",
       "          ...,\n",
       "          [ 0.46728122,  0.4636711 ,  0.45694208, ...,  0.33781362,\n",
       "            0.4800167 ,  0.47557247],\n",
       "          [ 0.49838623,  0.5025015 ,  0.5009048 , ...,  0.4094667 ,\n",
       "            0.4531396 ,  0.4632441 ],\n",
       "          [ 0.4675907 ,  0.4790392 ,  0.4935125 , ...,  0.4725275 ,\n",
       "            0.43700212,  0.46893162]],\n",
       " \n",
       "         [[ 0.149075  ,  0.16364709,  0.11829317, ...,  0.5367191 ,\n",
       "            0.53796995,  0.55246526],\n",
       "          [ 0.16971022,  0.20962629,  0.23705408, ...,  0.5522566 ,\n",
       "            0.5470506 ,  0.54871523],\n",
       "          [ 0.09418178,  0.09834859,  0.1640814 , ...,  0.5404778 ,\n",
       "            0.5422071 ,  0.53534955],\n",
       "          ...,\n",
       "          [ 0.4640069 ,  0.46039677,  0.45368695, ...,  0.33781362,\n",
       "            0.4800167 ,  0.47557247],\n",
       "          [ 0.48954356,  0.49365878,  0.49206036, ...,  0.4094667 ,\n",
       "            0.4531396 ,  0.4632441 ],\n",
       "          [ 0.45923394,  0.47068256,  0.4851557 , ...,  0.4725275 ,\n",
       "            0.43700212,  0.46893162]],\n",
       " \n",
       "         [[ 0.05789292,  0.06953627,  0.01753095, ...,  0.50733346,\n",
       "            0.5085843 ,  0.5230795 ],\n",
       "          [ 0.07318735,  0.10903049,  0.12732255, ...,  0.5138466 ,\n",
       "            0.50864035,  0.51030517],\n",
       "          [-0.01576877, -0.01083913,  0.05099228, ...,  0.49348575,\n",
       "            0.4952151 ,  0.4883575 ],\n",
       "          ...,\n",
       "          [ 0.46598583,  0.4623757 ,  0.4556543 , ...,  0.33781362,\n",
       "            0.4800167 ,  0.47557247],\n",
       "          [ 0.49488792,  0.49900314,  0.49740577, ...,  0.4094667 ,\n",
       "            0.4531396 ,  0.4632441 ],\n",
       "          [ 0.4642846 ,  0.47573316,  0.4902064 , ...,  0.4725275 ,\n",
       "            0.43700212,  0.46893162]]],\n",
       " \n",
       " \n",
       "        [[[ 1.2956852 ,  1.3239043 ,  1.2197547 , ...,  1.2680162 ,\n",
       "            1.2692758 ,  1.3350309 ],\n",
       "          [ 1.1905942 ,  1.2258734 ,  1.1225955 , ...,  1.1637163 ,\n",
       "            1.1712261 ,  1.2302767 ],\n",
       "          [ 1.1975068 ,  1.2014754 ,  1.0710137 , ...,  1.1458459 ,\n",
       "            1.1544555 ,  1.2199547 ],\n",
       "          ...,\n",
       "          [ 1.2195117 ,  1.2555705 ,  1.134487  , ...,  1.0810677 ,\n",
       "            1.0903953 ,  1.155966  ],\n",
       "          [ 1.321084  ,  1.369598  ,  1.2672449 , ...,  1.1791613 ,\n",
       "            1.2649714 ,  1.3291    ],\n",
       "          [ 1.2471969 ,  1.3082769 ,  1.2117503 , ...,  1.1863228 ,\n",
       "            1.1547382 ,  1.2210823 ]],\n",
       " \n",
       "         [[ 1.2763523 ,  1.3045714 ,  1.2004219 , ...,  1.2366813 ,\n",
       "            1.2379407 ,  1.3036962 ],\n",
       "          [ 1.1714712 ,  1.2067506 ,  1.1034728 , ...,  1.1323816 ,\n",
       "            1.1398913 ,  1.1989417 ],\n",
       "          [ 1.1672735 ,  1.171242  ,  1.0407807 , ...,  1.1145113 ,\n",
       "            1.1231208 ,  1.1886201 ],\n",
       "          ...,\n",
       "          [ 1.1794176 ,  1.2154765 ,  1.0943929 , ...,  1.031563  ,\n",
       "            1.0408905 ,  1.106461  ],\n",
       "          [ 1.2809896 ,  1.3295037 ,  1.2271508 , ...,  1.1276107 ,\n",
       "            1.2134207 ,  1.2775494 ],\n",
       "          [ 1.2071027 ,  1.2681825 ,  1.171656  , ...,  1.1348094 ,\n",
       "            1.103225  ,  1.169569  ]],\n",
       " \n",
       "         [[ 1.3231289 ,  1.3513478 ,  1.2471985 , ...,  1.3101873 ,\n",
       "            1.3114469 ,  1.3772022 ],\n",
       "          [ 1.218124  ,  1.2534035 ,  1.1501257 , ...,  1.2058876 ,\n",
       "            1.2133974 ,  1.272448  ],\n",
       "          [ 1.2204657 ,  1.2244344 ,  1.0939729 , ...,  1.1880172 ,\n",
       "            1.1966267 ,  1.2621262 ],\n",
       "          ...,\n",
       "          [ 1.2048501 ,  1.2409087 ,  1.1198254 , ...,  1.0269526 ,\n",
       "            1.03628   ,  1.1018506 ],\n",
       "          [ 1.3064222 ,  1.3549361 ,  1.252583  , ...,  1.1188964 ,\n",
       "            1.2047065 ,  1.2688351 ],\n",
       "          [ 1.2325351 ,  1.2936151 ,  1.1970884 , ...,  1.1261815 ,\n",
       "            1.094597  ,  1.160941  ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.6909839 ,  0.67267305,  0.65296453, ...,  0.6605014 ,\n",
       "            0.66909444,  0.67437387],\n",
       "          [ 0.6122477 ,  0.58637136,  0.558686  , ...,  0.58487105,\n",
       "            0.59558153,  0.5900898 ],\n",
       "          [ 0.5987356 ,  0.5673958 ,  0.5340582 , ...,  0.5633837 ,\n",
       "            0.5743532 ,  0.5760882 ],\n",
       "          ...,\n",
       "          [ 0.5817254 ,  0.56064665,  0.5493123 , ...,  0.5511811 ,\n",
       "            0.54419225,  0.5605388 ],\n",
       "          [ 0.703293  ,  0.68746644,  0.6786113 , ...,  0.6923025 ,\n",
       "            0.6849723 ,  0.6949423 ],\n",
       "          [ 0.6233871 ,  0.6073685 ,  0.6010528 , ...,  0.6308188 ,\n",
       "            0.6198245 ,  0.60370517]],\n",
       " \n",
       "         [[ 0.5972592 ,  0.5789483 ,  0.55923986, ...,  0.567063  ,\n",
       "            0.5755476 ,  0.58621037],\n",
       "          [ 0.518523  ,  0.4926467 ,  0.4649614 , ...,  0.49150136,\n",
       "            0.5020987 ,  0.5019258 ],\n",
       "          [ 0.5050109 ,  0.47367114,  0.44033352, ...,  0.46723688,\n",
       "            0.4782878 ,  0.48794737],\n",
       "          ...,\n",
       "          [ 0.5155668 ,  0.49448803,  0.48315376, ...,  0.47123942,\n",
       "            0.46425056,  0.48059726],\n",
       "          [ 0.63713443,  0.62130773,  0.6124526 , ...,  0.6123608 ,\n",
       "            0.60503066,  0.61500055],\n",
       "          [ 0.55722845,  0.54120994,  0.5348943 , ...,  0.55087715,\n",
       "            0.5398829 ,  0.52376354]],\n",
       " \n",
       "         [[ 0.60855275,  0.59024185,  0.57053345, ...,  0.5782342 ,\n",
       "            0.586987  ,  0.6020678 ],\n",
       "          [ 0.52981645,  0.5039402 ,  0.4762549 , ...,  0.50255704,\n",
       "            0.51343083,  0.51778424],\n",
       "          [ 0.51630443,  0.4849647 ,  0.45162705, ...,  0.48295617,\n",
       "            0.49395663,  0.5037668 ],\n",
       "          ...,\n",
       "          [ 0.51916057,  0.49808186,  0.48674747, ...,  0.47592637,\n",
       "            0.46893755,  0.48528415],\n",
       "          [ 0.6407281 ,  0.6249015 ,  0.6160464 , ...,  0.6170478 ,\n",
       "            0.6097177 ,  0.61968756],\n",
       "          [ 0.56082225,  0.5448036 ,  0.53848803, ...,  0.5555642 ,\n",
       "            0.54456997,  0.52845055]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[-0.49343443, -0.48231578, -0.4650164 , ..., -0.49716315,\n",
       "           -0.50642866, -0.52622557],\n",
       "          [-0.5216055 , -0.5118179 , -0.5022616 , ..., -0.52773786,\n",
       "           -0.5305335 , -0.5443568 ],\n",
       "          [-0.54416865, -0.53561306, -0.53585374, ..., -0.5659937 ,\n",
       "           -0.561579  , -0.56580925],\n",
       "          ...,\n",
       "          [-0.4450556 , -0.44925302, -0.4387007 , ..., -0.47493187,\n",
       "           -0.44944632, -0.42663008],\n",
       "          [-0.37305313, -0.3651111 , -0.37410063, ..., -0.432094  ,\n",
       "           -0.41342005, -0.3909281 ],\n",
       "          [-0.13192776, -0.12112784, -0.14701536, ..., -0.15749547,\n",
       "           -0.14494997, -0.12872203]],\n",
       " \n",
       "         [[-0.48985887, -0.47859025, -0.46621868, ..., -0.49364698,\n",
       "           -0.50291246, -0.52270937],\n",
       "          [-0.5180299 , -0.5080924 , -0.50346386, ..., -0.5242217 ,\n",
       "           -0.5270173 , -0.5408407 ],\n",
       "          [-0.54059315, -0.5318876 , -0.53705597, ..., -0.5624775 ,\n",
       "           -0.5580628 , -0.56229305],\n",
       "          ...,\n",
       "          [-0.44408813, -0.4482633 , -0.43532297, ..., -0.4771826 ,\n",
       "           -0.45169705, -0.4288808 ],\n",
       "          [-0.37211534, -0.3614499 , -0.36917347, ..., -0.43434474,\n",
       "           -0.4156708 , -0.39317885],\n",
       "          [-0.13095886, -0.12026538, -0.1437114 , ..., -0.15974621,\n",
       "           -0.14720073, -0.13097277]],\n",
       " \n",
       "         [[-0.56374156, -0.55247295, -0.53889906, ..., -0.55722046,\n",
       "           -0.566486  , -0.5862829 ],\n",
       "          [-0.5919126 , -0.5819751 , -0.5761443 , ..., -0.5877952 ,\n",
       "           -0.5905908 , -0.60441417],\n",
       "          [-0.61447585, -0.6057703 , -0.60973644, ..., -0.626051  ,\n",
       "           -0.6216363 , -0.62586653],\n",
       "          ...,\n",
       "          [-0.51281494, -0.51695704, -0.50882024, ..., -0.53163254,\n",
       "           -0.506147  , -0.4833308 ],\n",
       "          [-0.4408068 , -0.43332756, -0.44451728, ..., -0.48879468,\n",
       "           -0.4701207 , -0.44762877],\n",
       "          [-0.19968733, -0.18880744, -0.21712069, ..., -0.2141962 ,\n",
       "           -0.20165068, -0.1854227 ]]],\n",
       " \n",
       " \n",
       "        [[[ 0.0717863 , -0.03790178, -0.07886554, ..., -0.05847094,\n",
       "           -0.07885123, -0.14582534],\n",
       "          [ 0.18820055,  0.04568803, -0.04223673, ..., -0.05928154,\n",
       "           -0.14411546, -0.21111824],\n",
       "          [ 0.16154146,  0.17556083,  0.10859133, ..., -0.13972695,\n",
       "           -0.17877918, -0.18068075],\n",
       "          ...,\n",
       "          [ 0.63468325,  0.6221405 ,  0.63571084, ...,  0.5248201 ,\n",
       "            0.31755587,  0.22842416],\n",
       "          [ 0.6277704 ,  0.6105608 ,  0.61914027, ...,  0.6453874 ,\n",
       "            0.4486243 ,  0.2987103 ],\n",
       "          [ 0.63963103,  0.6178683 ,  0.62185234, ...,  0.6461685 ,\n",
       "            0.6361015 ,  0.44595456]],\n",
       " \n",
       "         [[ 0.04790986, -0.06177831, -0.10274197, ..., -0.06932003,\n",
       "           -0.0897003 , -0.15667443],\n",
       "          [ 0.1643241 ,  0.02181165, -0.06611323, ..., -0.07013059,\n",
       "           -0.15496455, -0.22196732],\n",
       "          [ 0.13766514,  0.15168446,  0.08471485, ..., -0.15057603,\n",
       "           -0.18962827, -0.19152984],\n",
       "          ...,\n",
       "          [ 0.56834835,  0.5559322 ,  0.56836367, ...,  0.5112587 ,\n",
       "            0.3039945 ,  0.21486282],\n",
       "          [ 0.558764  ,  0.5442909 ,  0.55187404, ...,  0.63182604,\n",
       "            0.435063  ,  0.28514892],\n",
       "          [ 0.5706749 ,  0.55159956,  0.5545068 , ...,  0.63260716,\n",
       "            0.6225402 ,  0.43239322]],\n",
       " \n",
       "         [[ 0.03755247, -0.07213564, -0.11309935, ..., -0.07803313,\n",
       "           -0.09841338, -0.16538754],\n",
       "          [ 0.15396672,  0.01145425, -0.07647059, ..., -0.07884365,\n",
       "           -0.16367765, -0.23068042],\n",
       "          [ 0.12730771,  0.14132705,  0.07435744, ..., -0.1592891 ,\n",
       "           -0.19834137, -0.20024294],\n",
       "          ...,\n",
       "          [ 0.56357384,  0.55117786,  0.56700945, ...,  0.50036734,\n",
       "            0.29310313,  0.20397145],\n",
       "          [ 0.5518438 ,  0.53948706,  0.55058473, ...,  0.62093467,\n",
       "            0.4241717 ,  0.2742575 ],\n",
       "          [ 0.5637954 ,  0.5467967 ,  0.5531538 , ...,  0.6217158 ,\n",
       "            0.6116488 ,  0.42150185]]],\n",
       " \n",
       " \n",
       "        [[[ 0.5012992 ,  0.47106677,  0.32775027, ...,  0.5178966 ,\n",
       "            0.59804773,  0.72638667],\n",
       "          [ 0.40091577,  0.3270421 ,  0.3643896 , ...,  0.49482062,\n",
       "            0.616303  ,  0.73649013],\n",
       "          [ 0.41847682,  0.29717746,  0.43477273, ...,  0.5667744 ,\n",
       "            0.59977007,  0.60678446],\n",
       "          ...,\n",
       "          [ 0.43876705,  0.49775928,  0.68496966, ...,  0.7085479 ,\n",
       "            0.6653845 ,  0.7909304 ],\n",
       "          [ 0.5674502 ,  0.724205  ,  0.80180264, ...,  0.73697436,\n",
       "            0.73059   ,  0.80969626],\n",
       "          [ 0.7102783 ,  0.90206724,  0.8760396 , ...,  0.793054  ,\n",
       "            0.81966084,  0.8651727 ]],\n",
       " \n",
       "         [[ 0.45156577,  0.430632  ,  0.29106954, ...,  0.40018386,\n",
       "            0.4658483 ,  0.5898094 ],\n",
       "          [ 0.3429935 ,  0.27601957,  0.32074204, ...,  0.36173385,\n",
       "            0.47289938,  0.5865258 ],\n",
       "          [ 0.34468645,  0.23954767,  0.3815159 , ...,  0.41123945,\n",
       "            0.43614316,  0.44217318],\n",
       "          ...,\n",
       "          [ 0.33274043,  0.40062425,  0.592802  , ...,  0.6108935 ,\n",
       "            0.58640045,  0.72142506],\n",
       "          [ 0.47264895,  0.630237  ,  0.7204715 , ...,  0.6438983 ,\n",
       "            0.64295554,  0.7374474 ],\n",
       "          [ 0.6024577 ,  0.80354077,  0.78199095, ...,  0.7062189 ,\n",
       "            0.7480304 ,  0.7996849 ]],\n",
       " \n",
       "         [[ 0.36951983,  0.35448557,  0.2374309 , ...,  0.2557416 ,\n",
       "            0.3059301 ,  0.41406024],\n",
       "          [ 0.2652462 ,  0.20951149,  0.27095592, ...,  0.21050483,\n",
       "            0.30367297,  0.4132159 ],\n",
       "          [ 0.2700372 ,  0.16755447,  0.32675603, ...,  0.2582426 ,\n",
       "            0.26560992,  0.26759723],\n",
       "          ...,\n",
       "          [ 0.23366773,  0.29764292,  0.49478528, ...,  0.47901374,\n",
       "            0.46152055,  0.6042763 ],\n",
       "          [ 0.38873172,  0.54749894,  0.63349044, ...,  0.50201726,\n",
       "            0.5209205 ,  0.62061846],\n",
       "          [ 0.52069545,  0.7178952 ,  0.6964165 , ...,  0.5520435 ,\n",
       "            0.6121522 ,  0.67257786]]]], dtype=float32)>}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset = create_tf_datasets(model_args['image_path_to_caption_file'], \n",
    "                                                model_args['images_dir'], \n",
    "                                                processor, \n",
    "                                                tokenizer, \n",
    "                                                train_split=model_args['train_split'])\n",
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/193 [..............................] - ETA: 2:40:06 - loss: 4.2151"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam')\n",
    "\n",
    "model.fit(train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=int(model_args['num_train_epochs'])\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('tesi_venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "803492ad2a6cc4aebddb9abb62d8046f007d39343d41ca3396425b5214d90182"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
